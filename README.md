# Ollama-Server
PHP Frontend for Hosting local LLM (run via vs code or basic php execute methods)
